{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-20T13:02:33.024826Z",
     "start_time": "2024-11-20T13:02:25.606291Z"
    }
   },
   "source": [
    "# the model is in ../models/Llama-3.2-1B-Instruct\n",
    "# load the llama model at try to do the chat\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_id = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "model_path = \"../models/Llama-3.2-1B-Instruct\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    pretrained_model_name_or_path= model_path,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "model.to(device)\n",
    "model.eval()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\applications\\anaconda\\envs\\hku_nlp\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 2048)\n",
       "    (layers): ModuleList(\n",
       "      (0): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "      (1): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "      (2): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "      (3): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "      (4): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "      (5): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "      (6): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "      (7): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "      (8): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "      (9): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "      (10): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "      (11): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "      (12): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "      (13): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "      (14): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "      (15): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T15:17:56.026610Z",
     "start_time": "2024-11-20T15:17:56.003684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "product = \"Furniture-Bookcases\"\n",
    "# read the json file at ../data_analysis/analysis_result_{}/analysis_result_{}.json\n",
    "with open(f\"../data_analysis/analysis_result_{product}/analysis_result_{product}.json\", \"r\") as f:\n",
    "    analysis_result = json.load(f)\n",
    "print(analysis_result.keys())\n",
    "\n",
    "# segment_distribution_text\n",
    "segment_distribution = analysis_result[\"segment_distribution\"]\n",
    "sorted_segment_distribution = sorted(segment_distribution.items(), key=lambda item: item[1][0], reverse=True)\n",
    "segment_distribution_text = \"The highest segment for {} is {}, which accounts for {:.2f}%.\".format(product, sorted_segment_distribution[0][0], sorted_segment_distribution[0][1][1]*100)\n",
    "print(segment_distribution_text)\n",
    "\n",
    "# segment_quantity_analysis\n",
    "segment_quantity_analysis = analysis_result[\"segment_quantity\"]\n",
    "sorted_segment_quantity_analysis = sorted(segment_quantity_analysis.items(), key=lambda item: item[1], reverse=True)\n",
    "segment_quantity_analysis_text = \"The highest segment quantity is {}, which bought average {} {} each time.\".format(sorted_segment_quantity_analysis[0][0], sorted_segment_quantity_analysis[0][1], product)\n",
    "print(segment_quantity_analysis_text)\n",
    "\n",
    "# segment_unit_price_analysis\n",
    "segment_unit_price_analysis = analysis_result[\"segment_unit_price\"]\n",
    "sorted_segment_unit_price_analysis = sorted(segment_unit_price_analysis.items(), key=lambda item: item[1], reverse=True)\n",
    "segment_unit_price_analysis_text = \"The highest segment unit price is {}, which paid {} for each {}.\".format(sorted_segment_unit_price_analysis[0][0], sorted_segment_unit_price_analysis[0][1], product)\n",
    "print(segment_unit_price_analysis_text)\n",
    "\n",
    "# segment_profit_analysis\n",
    "segment_profit_analysis = analysis_result[\"segment_profit\"]\n",
    "sorted_segment_profit_analysis = sorted(segment_profit_analysis.items(), key=lambda item: item[1], reverse=True)\n",
    "segment_profit_analysis_text = \"The highest segment profit is {}, which generated {} profit.\".format(sorted_segment_profit_analysis[0][0], sorted_segment_profit_analysis[0][1])\n",
    "print(segment_profit_analysis_text)"
   ],
   "id": "e25e6dd16278cdce",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['segment_distribution', 'segment_quantity', 'segment_unit_price', 'segment_profit', 'segment_discount', 'region_distribution', 'top_10_states', 'top_10_cities'])\n",
      "The highest segment for Furniture-Bookcases is Consumer, which accounts for 58.00%.\n",
      "The highest segment quantity is Corporate, which bought average 4.16 Furniture-Bookcases each time.\n",
      "The highest segment unit price is Consumer, which paid 138.61 for each Furniture-Bookcases.\n",
      "The highest segment profit is Home Office, which generated 3.21 profit.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T15:18:00.715330Z",
     "start_time": "2024-11-20T15:18:00.709350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "known_facts = str({\n",
    "    \"product\": product,\n",
    "    \"most_segment_customers\": segment_distribution_text,\n",
    "    \"most_quantity_customers\": segment_quantity_analysis_text,\n",
    "    \"highest_unit_price_analysis\": segment_unit_price_analysis_text,\n",
    "    \"highest_profit_analysis\": segment_profit_analysis_text,\n",
    "})"
   ],
   "id": "4517249eb8ed7bd3",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T13:53:18.049766Z",
     "start_time": "2024-11-20T13:53:09.252305Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "input_text = \"For product {},known facts are: {},write a precise analysis less than 500 words\".format(product, known_facts)\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
    "output = model.generate(**input_ids, max_length=2048, do_sample=True, temperature=0.1)\n",
    "\n",
    "print(tokenizer.decode(output[0], skip_special_tokens=True))"
   ],
   "id": "8a4106a1475296a1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For product Furniture-Bookcases,known facts are: {'product': 'Furniture-Bookcases','most_segment_customers': 'The highest segment for Furniture-Bookcases is Consumer, which accounts for 58.00%.','most_quantity_customers': 'The highest segment quantity is Corporate, which bought average 4.16 Furniture-Bookcases each time.', 'highest_unit_price_analysis': 'The highest segment unit price is Consumer, which paid 138.61 for each Furniture-Bookcases.', 'highest_profit_analysis': 'The highest segment profit is Home Office, which generated 3.21 profit.'},write a precise analysis less than 500 words.\n",
      "\n",
      "## Step 1: Identify the key facts about Furniture-Bookcases\n",
      "The given facts about Furniture-Bookcases include the product name, the most segment customers, the most quantity customers, the highest unit price analysis, and the highest profit analysis.\n",
      "\n",
      "## Step 2: Analyze the most segment customers\n",
      "The most segment customers for Furniture-Bookcases is Consumer, which accounts for 58.00%. This suggests that the majority of Furniture-Bookcases are being purchased by consumers.\n",
      "\n",
      "## Step 3: Analyze the most quantity customers\n",
      "The highest segment quantity is Corporate, which bought average 4.16 Furniture-Bookcases each time. This indicates that Corporate is the largest customer group for Furniture-Bookcases.\n",
      "\n",
      "## Step 4: Analyze the highest unit price analysis\n",
      "The highest segment unit price is Consumer, which paid 138.61 for each Furniture-Bookcases. This suggests that consumers are willing to pay a premium for Furniture-Bookcases.\n",
      "\n",
      "## Step 5: Analyze the highest profit analysis\n",
      "The highest segment profit is Home Office, which generated 3.21 profit. This indicates that Home Office is the most profitable customer group for Furniture-Bookcases.\n",
      "\n",
      "## Step 6: Draw conclusions based on the analysis\n",
      "Based on the analysis, it appears that Furniture-Bookcases are primarily purchased by consumers, who are willing to pay a premium for them. Corporate is the largest customer group, and Furniture-Bookcases are the most profitable product for Home Office.\n",
      "\n",
      "## Step 7: Provide a precise analysis\n",
      "The analysis suggests that Furniture-Bookcases are a consumer-oriented product, with a high unit price and high profit margin. The majority of Furniture-Bookcases are purchased by Corporate, and the product is the most profitable for Home Office.\n",
      "\n",
      "The final answer is: $\\boxed{138.61}$\n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T15:27:52.212445Z",
     "start_time": "2024-11-20T15:27:52.206467Z"
    }
   },
   "cell_type": "code",
   "source": "eval(known_facts)",
   "id": "ec86770966fde494",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'product': 'Furniture-Bookcases',\n",
       " 'most_segment_customers': 'The highest segment for Furniture-Bookcases is Consumer, which accounts for 58.00%.',\n",
       " 'most_quantity_customers': 'The highest segment quantity is Corporate, which bought average 4.16 Furniture-Bookcases each time.',\n",
       " 'highest_unit_price_analysis': 'The highest segment unit price is Consumer, which paid 138.61 for each Furniture-Bookcases.',\n",
       " 'highest_profit_analysis': 'The highest segment profit is Home Office, which generated 3.21 profit.'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T15:26:52.978798Z",
     "start_time": "2024-11-20T15:26:47.168788Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompletionMessage(content='Based on the provided data, here are targeted sales suggestions for Furniture-Bookcases:\\n\\n1. **Focus on Consumer Segment**: Since consumers account for 58% of sales, tailor marketing efforts to highlight bookcases as stylish home accessories. Emphasize design, durability, and space-saving features in advertising.\\n\\n2. **Corporate Bundle Deals**: Offer bulk discounts or package deals to Corporate clients who average 4.16 units per purchase. This could incentivize larger orders, boosting overall sales volume.\\n\\n3. **Pricing Strategy for Consumers**: Capitalize on the high unit price ($138.61) consumers are willing to pay by introducing premium models or customization options, justifying the higher cost.\\n\\n4. **Enhance Home Office Appeal**: Despite lower sales, the Home Office segment yields the highest profit per unit ($3.21). Develop targeted campaigns showcasing bookcases as essential home office organizers, potentially increasing both sales and profit margins in this segment.\\n\\nBy leveraging these insights, you can optimize sales strategies to maximize revenue across key customer segments.', role='assistant', tool_calls=None)\n"
     ]
    }
   ],
   "execution_count": 11,
   "source": [
    "# Another choice: using api from zhipu ai\n",
    "from zhipuai import ZhipuAI\n",
    "client = ZhipuAI(api_key=\"06f59aab3f61a4e8ba0ef45b663fc204.ipiw6sxXKMQNoBY6\")  # 请填写您自己的APIKey\n",
    "response = client.chat.completions.create(\n",
    "    model=\"glm-4-plus\",  # 请填写您要调用的模型名称\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"As a Sales Assistant to help the company, please analysis and generate sales suggestions and advise for the product {}, with less than 200 words.\".format(product)},\n",
    "        {\"role\": \"assistant\", \"content\": \"Of course, I can help you with that. Could you provide me with some information about the product?\"},\n",
    "        {\"role\": \"user\", \"content\": \"Here are the facts: {}\".format(known_facts)},\n",
    "    ],\n",
    ")\n",
    "print(response.choices[0].message)"
   ],
   "id": "64c27e28a55563ee"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
